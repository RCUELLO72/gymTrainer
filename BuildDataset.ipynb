{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import mxnet as mx\n",
    "import pickle\n",
    "\n",
    "from gluoncv import model_zoo\n",
    "from gluoncv.data.transforms.pose import detector_to_simple_pose, heatmap_to_coord\n",
    "from gluoncv.data.transforms.presets.ssd import transform_test\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initial steps\n",
    "\n",
    "# Loading pre-trained models\n",
    "detector = model_zoo.get_model('yolo3_mobilenet1.0_coco', pretrained=True)\n",
    "pose_net = model_zoo.get_model('simple_pose_resnet18_v1b', pretrained=True)\n",
    "#\n",
    "detector.reset_class([\"person\"], reuse_weights=['person'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this for your path(where the videos are)\n",
    "path_to_videos = \"/home/rcuello/SecondDisk/GymnVideoData\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of files from the path\n",
    "def process_directory_videos(source_path):\n",
    "    file_list = os.listdir(source_path)\n",
    "    dict_holder = {\n",
    "            \"PoseClipId\":0,\n",
    "            \"FileName\": \"\",\n",
    "            \"VideoSourceId\":0,\n",
    "            \"ExerciseType\" : \"\",\n",
    "            \"ClipNumber\":0,\n",
    "            \"SampleType\":\"\"\n",
    "    }\n",
    "    df = pd.DataFrame(columns=['PoseClipId','FileName','VideoSourceId',\n",
    "                               'ExerciseType','ClipNumber','SampleType',\n",
    "                               'CroppedPerson','ExtraPerson','NumberOfFrames'])\n",
    "    \n",
    "    for video_file in file_list:\n",
    "        spl_fname = video_file.split(sep='_')\n",
    "        dict_holder[\"PoseClipId\"] = abs(hash(video_file)) % (10 ** 8)\n",
    "        dict_holder[\"FileName\"] = video_file\n",
    "        dict_holder[\"VideoSourceId\"] = spl_fname[0]\n",
    "        dict_holder[\"ExerciseType\"] = spl_fname[1]\n",
    "        dict_holder[\"ClipNumber\"] = spl_fname[2]\n",
    "        dict_holder[\"SampleType\"] = spl_fname[3].split(sep='.')[0]\n",
    "        dict_holder[\"CroppedPerson\"] = 0\n",
    "        dict_holder[\"ExtraPerson\"] = 0\n",
    "        dict_holder[\"NumberOfFrames\"] = 0\n",
    "        df = df.append(dict_holder,ignore_index=True)\n",
    "        \n",
    "    return(df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_dims(a_frame):\n",
    "    \"\"\"\n",
    "    As the video contains a black box around it, this\n",
    "    function calculates the coordiantes to get rid of it\n",
    "    \"\"\"\n",
    "    gray = cv.cvtColor(a_frame,cv.COLOR_BGR2GRAY)\n",
    "    _,thresh = cv.threshold(gray,1,255,cv.THRESH_BINARY)\n",
    "    contours = cv.findContours(thresh,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE)\n",
    "    cntB = contours[0]\n",
    "    return cv.boundingRect(cntB)  # x,y,w,h = cv.boundingRect(cntB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_frames(source_path,video_file):\n",
    "    \"\"\"\n",
    "    Process a single video file. The function selects the second frame for\n",
    "    every second of the video, crop it if it is needed, and create an array\n",
    "    of frames for future processing, e.g keypoint determination. \n",
    "    \"\"\"\n",
    "    frame_list = []\n",
    "    full_path = os.path.join(source_path,video_file)\n",
    "    video_cap = cv.VideoCapture(full_path)\n",
    "    n_fps = int(video_cap.get(cv.CAP_PROP_FPS))    \n",
    "    cnt =1\n",
    "    if video_cap.isOpened():\n",
    "        ret, frame = video_cap.read()\n",
    "        # Use first frame to get black box \n",
    "        x,y,w,h = get_crop_dims(frame) \n",
    "        print('Cropped Size:',w-x+1,h-y+1)\n",
    "        while (video_cap.isOpened()):\n",
    "            ret, frame = video_cap.read()\n",
    "            if ret == True:\n",
    "                if cnt==n_fps:\n",
    "                    cropped_frame = frame[y:y+h,x:x+w]\n",
    "                    # Converting now the the fram to RGB\n",
    "                    rgb_frame = cv.cvtColor(cropped_frame, cv.COLOR_BGR2RGB)\n",
    "                    frame_list.append(mx.nd.array(rgb_frame).astype('uint8'))\n",
    "                    cnt=1\n",
    "                else:\n",
    "                    cnt+=1\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        print('Error opening the file')\n",
    "    video_cap.release()\n",
    "    return frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_frame_info(a_frame):\n",
    "    x, frame = transform_test(a_frame, short=512)\n",
    "    class_IDs, scores, bounding_boxs = detector(x)\n",
    "    pose_input, upscale_bbox = detector_to_simple_pose(frame, class_IDs, scores, bounding_boxs)\n",
    "    if len(upscale_bbox)>0:\n",
    "        predicted_heatmap = pose_net(pose_input)\n",
    "        pred_coords, confidence = heatmap_to_coord(predicted_heatmap, upscale_bbox)\n",
    "        pred_coords = pred_coords.asnumpy()\n",
    "    return  class_IDs, scores, upscale_bbox, pred_coords, confidence, bounding_boxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skeleton_from_frame(a_frame):\n",
    "    ok_flag = False\n",
    "    extra_person_flag = False\n",
    "    x, frame = transform_test(a_frame, short=512)\n",
    "    class_IDs, scores, bounding_boxs = detector(x)\n",
    "    pose_input, upscale_bbox = detector_to_simple_pose(frame, class_IDs, scores, bounding_boxs)\n",
    "    b_coords = 0\n",
    "    if len(upscale_bbox)>0:\n",
    "        predicted_heatmap = pose_net(pose_input)\n",
    "        pred_coords, confidence = heatmap_to_coord(predicted_heatmap, upscale_bbox)\n",
    "        pred_coords = pred_coords.asnumpy()\n",
    "        b_coords = pred_coords[0]\n",
    "        if pred_coords.shape[0]>2:\n",
    "            extra_person_flag = True\n",
    "        if pred_coords.shape[0]==2:\n",
    "            # doing best guest when two boxes ( subject and background are similar)\n",
    "            if upscale_bbox[0][3]==512:\n",
    "                b_coords = pred_coords[1]\n",
    "        ok_flag= True\n",
    "    return ok_flag, extra_person_flag, b_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skeletons(frame_list):\n",
    "    \"\"\"\n",
    "    Process all frames and returns skeleton list\n",
    "    \"\"\"\n",
    "    skeleton_coords = []\n",
    "    nr_frames = len(frame_list)\n",
    "    frame_box_ok = np.zeros(nr_frames, dtype='uint8')\n",
    "    extra_person = np.zeros(nr_frames, dtype='uint8')\n",
    "    print('# frames :',nr_frames)\n",
    "    fs =0\n",
    "    for a_frame in frame_list:\n",
    "        ok_flag, extra_flag, frame_skeleton = get_skeleton_from_frame(a_frame)\n",
    "        msg='  '\n",
    "        if not ok_flag:\n",
    "            msg = msg + ':CROPPPED PERSON'\n",
    "        if extra_flag:\n",
    "            msg = msg + ':MULTIPLE PERSONS'\n",
    "        print(fs+1,msg,end=' ')\n",
    "        if not ok_flag:\n",
    "            frame_box_ok[fs] = 1\n",
    "        if extra_flag:\n",
    "            extra_person[fs] = 1\n",
    "        fs = fs + 1        \n",
    "        skeleton_coords.append(frame_skeleton)\n",
    "            \n",
    "    print('Finished file.')\n",
    "    return frame_box_ok, extra_person, skeleton_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_videos(source_path,save_file_name=\"GymnData.pickle\"):\n",
    "    print('Reading directory...')\n",
    "    clip_list = process_directory_videos(source_path)\n",
    "    print('Finished')\n",
    "    print()\n",
    "    skeletons = {}\n",
    "    cropped_person = {}\n",
    "    extra_person = {}\n",
    "    for index, a_file in clip_list.iterrows():\n",
    "        fname = a_file['FileName']\n",
    "        clip_id = a_file['PoseClipId']\n",
    "        print(' Processing ',fname,' -> ClipID=',clip_id)\n",
    "        video_frames=get_video_frames(source_path,fname)\n",
    "        cropped_person[clip_id], extra_person[clip_id],skeletons[clip_id] = get_skeletons(video_frames) \n",
    "        a_file['CroppedPerson'] = np.sum(cropped_person[clip_id])\n",
    "        a_file['ExtraPerson'] = np.sum(extra_person[clip_id])\n",
    "        a_file['NumberOfFrames'] = len(extra_person[clip_id])\n",
    "    dataset = {}\n",
    "    dataset[\"ClipList\"] = clip_list\n",
    "    dataset[\"Skeletons\"] = skeletons\n",
    "    dataset[\"CroppedPerson\"] = cropped_person\n",
    "    dataset[\"ExtraPerson\"] = extra_person\n",
    "    with open(save_file_name,'wb') as f:\n",
    "        pickle.dump(dataset,f)\n",
    "    return(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main program, scrap videos and save skeleton data into pickle file\n",
    "my_dataset = scrap_videos(path_to_videos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
